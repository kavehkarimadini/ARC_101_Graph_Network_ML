{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee929f63-3429-4bba-b778-d4696914ee70",
   "metadata": {},
   "source": [
    "# we will use [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) packages to help us implement \n",
    "relational GCN for heterogeneous graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0dbd2-2076-4074-a619-ed94b53bb264",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4a07b4-3ce7-49c7-aa08-595fdaadeee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ff536a-3f5f-49ab-8d18-6282e972b60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (2.5.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (4.66.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (1.10.1)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (3.1.3)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (3.9.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (5.9.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from aiohttp->torch-geometric) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from aiohttp->torch-geometric) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from jinja2->torch-geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from requests->torch-geometric) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from requests->torch-geometric) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from requests->torch-geometric) (2024.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d7b610e-567c-4a40-8594-de8cbb4ef155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (3.1)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (6.1.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install networkx matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c14805-93b8-4fcc-8ae0-d5f7935b44ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (7.1.4)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.7.2 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from rdflib) (0.7.2)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from rdflib) (3.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rdflib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d6e3d-97dd-4702-8400-ba049fd02be5",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries\n",
    "PyTorch Geometric has two classes for storing and/or transforming graphs into tensor format. One is `torch_geometric.datasets`, which contains a variety of common graph datasets. Another is `torch_geometric.data`, which provides the data handling of graphs in PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9544eba7-daa3-4226-bafd-b0bd3deb2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import RGCNConv\n",
    "from torch_geometric.datasets import Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9374f2c-8fb3-48ba-a66f-fe1894976dce",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "The AIFB dataset describes the AIFB research institute in terms of its staff, research group, and publications. In (Bloehdorn et al 2007) the dataset was first used to predict the affiliation (i.e., research group) for people in the dataset. \n",
    "In its standard setting, the dataset includes:\n",
    "  1. A multi-relational graph structure\n",
    "  2. ~150 labeled Person nodes across 4 research group classes (used for supervised classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5cbfe1a-24f2-4499-94b3-d2cd1601132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load the AIFB dataset (a knowledge graph with multiple relation types)\n",
    "dataset = Entities(root='/tmp/AIFB', name='AIFB')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f37c55-d81b-4031-bc20-9a3283ccf173",
   "metadata": {},
   "source": [
    "## the number of classes and number of relations in the AIFB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a94525-2a90-4279-bbf2-1244523899dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIFB dataset has 8285 nodes\n",
      "AIFB dataset has 58086 edges\n",
      "AIFB dataset has 4 classes\n",
      "AIFB dataset has 90 relations\n",
      "Dataset attribute information: Data(edge_index=[2, 58086], edge_type=[58086], train_idx=[140], train_y=[140], test_idx=[36], test_y=[36], num_nodes=8285)\n"
     ]
    }
   ],
   "source": [
    "def basic_info(dataset, data):\n",
    "    # TODO: Implement a function that takes a PyG dataset object\n",
    "    # and returns the number of classes, number of features for that dataset.\n",
    "    num_class = 0\n",
    "    num_relations = 0\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    num_edges = data.num_edges\n",
    "    ############# Your code here ############\n",
    "    ## (~2 lines of code)\n",
    "    num_class = dataset.num_classes\n",
    "    num_relations = dataset.num_relations\n",
    "    #########################################\n",
    "    print(\"AIFB dataset has {} nodes\".format(num_nodes))\n",
    "    print(\"AIFB dataset has {} edges\".format(num_edges))\n",
    "    print(\"AIFB dataset has {} classes\".format(num_class))\n",
    "    print(\"AIFB dataset has {} relations\".format(num_relations))\n",
    "    print('Dataset attribute information:', data)\n",
    "    \n",
    "basic_info(dataset, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01442110-707c-4d06-bcc1-28e0a76e1300",
   "metadata": {},
   "source": [
    "## Get familar with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33b15d1c-fcfe-42ad-9a3a-17643d4a2649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_type attribute: tensor([21,  9, 13,  ..., 13, 27, 59])\n",
      "edge_type attribute: torch.Size([58086])\n",
      "edge_type attribute (min): 0\n",
      "edge_type attribute (max): 89\n"
     ]
    }
   ],
   "source": [
    "# From the above exercise, we know that the number of relations is 90\n",
    "# Now print out the edge type to see if the they range from 0 to 89 (90 different relation types).\n",
    "print(f'edge_type attribute: {data.edge_type}') # a tensor of size 58086 (number of edges), each element is the edge type for that edge. \n",
    "print(f'edge_type attribute: {data.edge_type.shape}')\n",
    "\n",
    "print(f'edge_type attribute (min): {min(data.edge_type)}')\n",
    "print(f'edge_type attribute (max): {max(data.edge_type)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0de6ff3-53a1-4cde-80e4-225fe026b1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training node indices:\n",
      "tensor([1338, 6081, 7902, 7564, 4002, 7309, 4963, 6520, 6492,  429, 4838, 7762,\n",
      "         414, 4422, 8217, 3371, 1088, 8110, 4314, 2531, 2417, 1982, 5844, 6982,\n",
      "        5432, 8258, 2020, 1725, 4250, 5489, 2083, 8141,  317, 2651, 8067, 5394,\n",
      "         372,   37, 6159, 7654, 7927, 7327, 5574,  286, 4101, 6645, 5061, 2194,\n",
      "        5719,  494, 2778, 7813, 4745, 3127, 5329, 5290, 6885, 5473, 4195, 7086,\n",
      "        3132,  240, 5284, 7648, 7590, 6133, 3300, 2597, 3523, 2189, 6400, 7887,\n",
      "        4854,   31, 1920, 6244, 1769,  138, 2984, 6639, 4204, 5184, 1566, 6550,\n",
      "        7819, 6971, 6619, 7274, 1413,  140, 2644, 6415, 5086,   98, 3634, 8181,\n",
      "        3893, 6193, 5274,    8, 6047, 6553, 3704, 5024, 8215, 3251, 1303, 1102,\n",
      "        3613, 4707, 7907,  872, 7142, 4016, 2774, 7180, 7455, 5095, 5320, 7219,\n",
      "        3220, 7600, 5056, 4242, 2876, 6241, 4870, 6375,  510, 5878, 5493, 7264,\n",
      "        1086, 2095, 5695, 5325, 3783, 4361, 3737, 2523])\n",
      "Corresponding training labels (4 classes, 0-3):\n",
      "tensor([1, 2, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 3, 2, 3, 3, 2, 1,\n",
      "        2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 0, 3, 3, 2, 0, 1, 1, 2, 3, 1, 1, 2, 1,\n",
      "        0, 1, 0, 1, 2, 2, 1, 2, 2, 2, 1, 1, 3, 3, 2, 1, 1, 2, 2, 3, 1, 1, 2, 3,\n",
      "        1, 3, 2, 1, 2, 1, 1, 3, 1, 3, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1, 0, 1, 1, 1,\n",
      "        3, 2, 3, 3, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 3, 1, 2, 1, 0, 0, 1, 1, 1, 3,\n",
      "        0, 2, 1, 1, 1, 1, 0, 2, 2, 1, 2, 3, 2, 0, 1, 1, 2, 1, 0, 3])\n",
      "The size of training set:\n",
      "torch.Size([140])\n",
      "=========================================\n",
      "5673 in-edges to training nodes\n",
      "5673 out-edges to training nodes\n",
      "The corresponding in-edges to training nodes:\n",
      "tensor([[   0,    0,    4,  ..., 8282, 8282, 8282],\n",
      "        [3613, 3613, 3613,  ..., 1413, 5432, 5432]])\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "# When training we need to use the data.train_idx, which is the indices of the nodes we can use for training.\n",
    "# train_y is the corresponding labels (4 classes, 0-3) for these nodes\n",
    "print (\"Training node indices:\")\n",
    "print (data.train_idx)\n",
    "print (\"Corresponding training labels (4 classes, 0-3):\")\n",
    "print (data.train_y)\n",
    "print (\"The size of training set:\")\n",
    "print (data.train_y.shape)\n",
    "print (\"=========================================\")\n",
    "\n",
    "# We can also use data.train_idx to get the corresponding edges\n",
    "# This finds all edges connected to nodes in data.train_idx. \n",
    "# It checks whether the source or target node of an edge is part of the training node set.\n",
    "train_in_edge_mask = torch.isin(data.edge_index[1,:], data.train_idx)\n",
    "print(f\"{train_in_edge_mask.sum()} in-edges to training nodes\")\n",
    "train_out_edge_mask = torch.isin(data.edge_index[0,:], data.train_idx)\n",
    "print(f\"{train_out_edge_mask.sum()} out-edges to training nodes\")\n",
    " \n",
    "# Each column represents one edge\n",
    "print (\"The corresponding in-edges to training nodes:\")\n",
    "print (data.edge_index[:,train_in_edge_mask])\n",
    "print (\"=========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19f0426-07e0-45a2-8d91-59ed9ec06705",
   "metadata": {},
   "source": [
    "## Play with the dataset with test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a898ba9a-4d35-4bd6-b169-78d748aed9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing node indices:\n",
      "tensor([3780, 6442, 2057, 5698, 6294,  355, 1045, 5175, 3813, 7809, 6510, 7574,\n",
      "          64, 3710, 1235,  888, 5799, 5817, 2750, 7477,  830, 4571,  139,  581,\n",
      "        1340, 6902, 6087, 3745,  903,  759, 3635, 1999, 7563, 6556, 5013, 7899])\n",
      "Corresponding testing labels (4 classes, 0-3):\n",
      "tensor([1, 2, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 3, 0, 2, 2, 1, 2, 2,\n",
      "        3, 3, 2, 2, 1, 2, 1, 3, 0, 1, 3, 0])\n",
      "The size of training dataset:\n",
      "torch.Size([36])\n",
      "=========================================\n",
      "The corresponding edges:\n",
      "1550 in-edges to test nodes\n",
      "1550 out-edges to test nodes\n",
      "The corresponding in-edges to test nodes:\n",
      "tensor([[  27,   53,   53,  ..., 8269, 8281, 8281],\n",
      "        [6087,  581,  581,  ...,  139, 6087, 6087]])\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "print (\"Testing node indices:\")\n",
    "#############################\n",
    "# TODO: print the test set indices\n",
    "# ~ 1 line of code\n",
    "print (data.test_idx)\n",
    "#############################\n",
    "\n",
    "print (\"Corresponding testing labels (4 classes, 0-3):\")\n",
    "#############################\n",
    "# TODO: print the corresponding test set labels\n",
    "# ~ 1 line of code\n",
    "print (data.test_y)\n",
    "#############################\n",
    "\n",
    "print (\"The size of training dataset:\")\n",
    "#############################\n",
    "# TODO: print the size of the test set\n",
    "# ~ 1 line of code\n",
    "print (data.test_y.shape)\n",
    "#############################\n",
    "print (\"=========================================\")\n",
    "\n",
    "\n",
    "print (\"The corresponding edges:\")\n",
    "#############################\n",
    "\n",
    "# We can also use data.test_idx to get the corresponding edges\n",
    "# This finds all edges connected to nodes in data.test_idx.\n",
    "# It checks whether the source or target node of an edge is part of the test node set.\n",
    "test_in_edge_mask = torch.isin(data.edge_index[1, :], data.test_idx)\n",
    "print(f\"{test_in_edge_mask.sum()} in-edges to test nodes\")\n",
    "\n",
    "test_out_edge_mask = torch.isin(data.edge_index[0, :], data.test_idx)\n",
    "print(f\"{test_out_edge_mask.sum()} out-edges to test nodes\")\n",
    "\n",
    "# Each column represents one edge\n",
    "print(\"The corresponding in-edges to test nodes:\")\n",
    "print(data.edge_index[:, test_in_edge_mask])\n",
    "print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2274a80-b47f-4fd9-8324-870861c1e0b2",
   "metadata": {},
   "source": [
    "## Build RGCN model\n",
    "we will implement **Relational GCN** covered in week 8.\n",
    "\n",
    "As taught in the lecture, in an RGCN layer, each node gathers information from its neighbors—but crucially, this aggregation is performed separately for each relation type. Each relation type has its own learnable weight matrix, allowing the network to capture how different kinds of connections contribute uniquely to a node's representation. After processing messages from all relation types, these relation-specific contributions are combined (typically via summation) along with the node’s own transformed features (often using a self-loop). By stacking multiple RGCN layers, the network can aggregate multi-relational information from increasingly larger neighborhoods, enabling it to model complex interactions in heterogeneous graphs.\n",
    "\n",
    "\n",
    "PyG implements this layer via [`RGCNConv`](https://pytorch-geometric.readthedocs.io/en/stable/generated/torch_geometric.nn.conv.RGCNConv.html), which can be executed by passing in the node feature representation `x`, the COO graph connectivity representation `edge_index`, and the one-dimensional relation type/index `edge_type` for each edge in `edge_index`. By passing values to `num_bases`, this layer will use the basis-decomposition regularization scheme where num_bases denotes the number of bases to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c51ff5-8912-4d79-93b3-1005cc9d657b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No node features detected; using a learnable node embedding.\n"
     ]
    }
   ],
   "source": [
    "# Check for node features. AIFB typically does not provide node features.\n",
    "# So we need to learn a node embeddings using just the node ids.\n",
    "if data.x is None:\n",
    "    print(\"No node features detected; using a learnable node embedding.\")\n",
    "    use_embedding = True\n",
    "else:\n",
    "    use_embedding = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b8b7197-746f-489a-9036-2f0624b0f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RGCN model\n",
    "class RGCN(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, in_channels, hidden_channels, out_channels, num_relations, num_bases=10, use_embedding=False):\n",
    "        super(RGCN, self).__init__()\n",
    "        \n",
    "        # If use embedding, use torch.nn.Embedding for learnable node embedding to map nodes into in_channels.\n",
    "        self.use_embedding = use_embedding\n",
    "        if use_embedding:\n",
    "            self.embedding = torch.nn.Embedding(num_nodes, in_channels)\n",
    "        ######################\n",
    "        # TO DO:\n",
    "        # 1. Define 2 RGCN layers using RGCNConv\n",
    "        # You can set num_bases to use basis learning for regularization. \n",
    "        # ~ 2 lines of code\n",
    "        self.conv1 = RGCNConv(in_channels, hidden_channels, num_relations, num_bases=num_bases)\n",
    "        self.conv2 = RGCNConv(hidden_channels, out_channels, num_relations, num_bases=num_bases)\n",
    "        ######################\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        ######################\n",
    "        # TODO:\n",
    "        # Implement the function which takes in the node input x and\n",
    "        # edge_index tensor and edge_type tensor and returns the prediction. \n",
    "        # Hint: Use the embedding layer and two RGCN layers defined in the above function.\n",
    "        # Do not forget the activation function\n",
    "        # You can also apply dropout\n",
    "        if self.use_embedding:\n",
    "            x = self.embedding(x)\n",
    "        x = self.conv1(x, edge_index, edge_type)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        ######################\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d34891-b9a8-41c2-8932-539c9ad75677",
   "metadata": {},
   "source": [
    "## Exercise 4: Skip connection in RGCN model\n",
    "In this exercise, we will implement skip connections in **Relational GCN**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8494ea64-ea4b-43c2-b05a-0af04917de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN2(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, in_channels, hidden_channels, out_channels, num_relations, num_bases=10, use_embedding=False):\n",
    "        super(RGCN2, self).__init__()\n",
    "        \n",
    "        self.use_embedding = use_embedding\n",
    "        if use_embedding:\n",
    "            self.embedding = torch.nn.Embedding(num_nodes, in_channels)\n",
    "        \n",
    "        ######################\n",
    "        # TO DO:\n",
    "        # 1. Define 3 RGCN layers using RGCNConv\n",
    "        # You can set num_bases to use basis learning for regularization. \n",
    "        # ~ 3 lines of code\n",
    "        self.conv1 = RGCNConv(in_channels, in_channels, num_relations, num_bases=num_bases)\n",
    "        self.conv2 = RGCNConv(in_channels, hidden_channels, num_relations, num_bases=num_bases)\n",
    "        self.conv3 = RGCNConv(hidden_channels, out_channels, num_relations, num_bases=num_bases)\n",
    "    \n",
    "        ######################\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        if self.use_embedding:\n",
    "            x = self.embedding(x)\n",
    "        \n",
    "        ######################\n",
    "        # TODO:\n",
    "        # 1. Implement skip connection.\n",
    "        # 2. Return the prediction output.\n",
    "        \n",
    "        x_input = x  # Save original input for skip connection\n",
    "        x = self.conv1(x, edge_index, edge_type)\n",
    "        x = F.relu(x)\n",
    "        x = x + x_input # the dimensions needs to be match. \n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        x = self.conv3(x, edge_index, edge_type)\n",
    "\n",
    "        #######################\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee7290-dadd-4fdc-90df-69a1a77964e3",
   "metadata": {},
   "source": [
    "## Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d4d46d2-61d2-423e-91db-e2a99cac758a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 1.9114, Train Acc: 0.4714, Test Acc: 0.3889\n",
      "Epoch: 010, Loss: 0.6358, Train Acc: 0.8214, Test Acc: 0.6667\n",
      "Epoch: 020, Loss: 0.3286, Train Acc: 0.9500, Test Acc: 0.8056\n",
      "Epoch: 030, Loss: 0.1364, Train Acc: 0.9857, Test Acc: 0.7778\n",
      "Epoch: 040, Loss: 0.0695, Train Acc: 0.9857, Test Acc: 0.8333\n",
      "Epoch: 050, Loss: 0.0491, Train Acc: 1.0000, Test Acc: 0.8333\n",
      "Epoch: 060, Loss: 0.0350, Train Acc: 1.0000, Test Acc: 0.8333\n",
      "Epoch: 070, Loss: 0.0223, Train Acc: 1.0000, Test Acc: 0.8333\n",
      "Epoch: 080, Loss: 0.0227, Train Acc: 1.0000, Test Acc: 0.8333\n",
      "Epoch: 090, Loss: 0.0154, Train Acc: 1.0000, Test Acc: 0.8333\n"
     ]
    }
   ],
   "source": [
    "# Set up device and prepare input features.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if use_embedding:\n",
    "    # When using embeddings, use node indices as input.\n",
    "    input_x = torch.arange(data.num_nodes, device=device)\n",
    "else:\n",
    "    input_x = data.x.to(device)\n",
    "\n",
    "# Create the model.\n",
    "# You can use either RGCN and RGCN2 built above for training and evaluation.\n",
    "model = RGCN(num_nodes=data.num_nodes,\n",
    "             in_channels=32,           # Adjust based on your needs.\n",
    "             hidden_channels=64,\n",
    "             out_channels=dataset.num_classes,\n",
    "             num_relations=dataset.num_relations,\n",
    "             num_bases=10,\n",
    "             use_embedding=use_embedding).to(device)\n",
    "\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(input_x, data.edge_index, data.edge_type)\n",
    "    # Compute cross-entropy loss on training nodes (assuming data.train_idx exists)\n",
    "    loss = F.cross_entropy(out[data.train_idx], data.train_y.squeeze())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(input_x, data.edge_index, data.edge_type)\n",
    "    pred = out.argmax(dim=1)\n",
    "    train_correct = pred[data.train_idx].eq(data.train_y.squeeze()).sum().item()\n",
    "    test_correct = pred[data.test_idx].eq(data.test_y.squeeze()).sum().item()\n",
    "    train_acc = train_correct / data.train_idx.size(0)\n",
    "    test_acc = test_correct / data.test_idx.size(0)\n",
    "    return train_acc, test_acc\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(0, 100):\n",
    "    loss = train()\n",
    "    train_acc, test_acc = test()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6867598-a7dc-49da-9f3d-d221a930def1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kaveh)",
   "language": "python",
   "name": "kaveh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
