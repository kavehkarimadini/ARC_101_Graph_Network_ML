{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdea6eeb-9ea1-4b68-a86f-720499ce605c",
   "metadata": {},
   "source": [
    "# we will use [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) packages to help us implement graph neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef996527-286a-469f-9b52-c1f95803354f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f305829-78e0-4a5a-8c87-eed89010f653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03fb7efb-4629-4857-9375-c0aaa40c5d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (2.5.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (4.66.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (1.24.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (1.10.1)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (3.1.3)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (3.9.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from torch-geometric) (5.9.8)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from aiohttp->torch-geometric) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from aiohttp->torch-geometric) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from aiohttp->torch-geometric) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from jinja2->torch-geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from requests->torch-geometric) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from requests->torch-geometric) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from requests->torch-geometric) (2024.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from scikit-learn->torch-geometric) (3.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b45d6f32-e327-4c0b-b2f8-6439b1343409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (3.1)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from matplotlib) (6.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/py38/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install networkx matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8abf13-6823-43b5-9cff-efbe3170193c",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries\n",
    "PyTorch Geometric has two classes for storing and/or transforming graphs into tensor format. One is `torch_geometric.datasets`, which contains a variety of common graph datasets. Another is `torch_geometric.data`, which provides the data handling of graphs in PyTorch tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57eb743b-1499-4362-8e04-a5ece7417f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.nn import GCNConv, BatchNorm\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266264e-bdb4-4a28-910a-54454c65ee15",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "ENZYMES is a dataset of 600 protein tertiary structures obtained from the BRENDA enzyme database. \n",
    "Each graph in the ENZYMES dataset corresponds to a protein, and proteins are classified into one of 6 EC (Enzyme Commission) top-level classes. These classes are based on the type of chemical reaction the enzyme catalyzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0564f94b-8c11-4418-a3c6-78cc4d734921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load the ENZYMES dataset\n",
    "dataset = TUDataset(root='/tmp/enzymes', name='ENZYMES')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdaf16e-fc9f-4e02-8d1b-249adb97e980",
   "metadata": {},
   "source": [
    "## What is the number of classes and number of features in the ENZYMES dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1060c322-d1ec-40fa-a18f-80074c4fe441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES dataset has 6 classes\n",
      "ENZYMES dataset has 3 features\n"
     ]
    }
   ],
   "source": [
    "def basic_info(dataset):\n",
    "    # TODO: Implement a function that takes a PyG dataset object\n",
    "    # and returns the number of classes, number of features for that dataset.\n",
    "    num_class = 0\n",
    "    num_features = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~2 lines of code)\n",
    "    num_class = dataset.num_classes\n",
    "    num_features = dataset.num_features\n",
    "    #########################################\n",
    "\n",
    "    return num_class, num_features\n",
    "\n",
    "num_classes, num_features = basic_info(dataset)\n",
    "print(\"ENZYMES dataset has {} classes\".format(num_classes))\n",
    "print(\"ENZYMES dataset has {} features\".format(num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf691d0c-65c6-4bdc-a83c-8cf899c48b24",
   "metadata": {},
   "source": [
    "## What is the label of the graph with index 100 in the ENZYMES dataset?\n",
    "Each PyG dataset stores a list of `torch_geometric.data.Data` objects, where each `torch_geometric.data.Data` object represents a graph. We can easily get the `Data` object by indexing into the dataset.\n",
    "\n",
    "For more information such as what is stored in the `Data` object, please refer to the [documentation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80445f42-a407-4fd7-ae9f-d92870c10a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 176], x=[45, 3], y=[1])\n",
      "Graph with index 100 has label 4\n"
     ]
    }
   ],
   "source": [
    "def get_graph_class(dataset, idx):\n",
    "    # TODO: Implement a function that takes a PyG dataset object,\n",
    "    # an index of a graph within the dataset, and returns the class/label\n",
    "    # of the graph (as an integer).\n",
    "\n",
    "    label = -1\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    label = int(dataset[idx].y)\n",
    "    #########################################\n",
    "\n",
    "    return label\n",
    "    \n",
    "idx = 100\n",
    "single_graph = dataset[idx]\n",
    "label = get_graph_class(dataset, idx)\n",
    "print(single_graph)\n",
    "print('Graph with index {} has label {}'.format(idx, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797eb296-c0a7-45c5-a005-dea0b0b30778",
   "metadata": {},
   "source": [
    "## How many edges does the graph with index 100 have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6130ba9e-f9ef-4084-943f-36afe957530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with index 100 has 88 edges\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def get_graph_num_edges(dataset, idx):\n",
    "    # TODO: Implement a function that takes a PyG dataset object,\n",
    "    # the index of a graph in the dataset, and returns the number of\n",
    "    # edges in the graph (as an integer). You should not count an edge\n",
    "    # twice if the graph is undirected. For example, in an undirected\n",
    "    # graph G, if two nodes v and u are connected by an edge, this edge\n",
    "    # should only be counted once.\n",
    "\n",
    "    num_edges = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## Note:\n",
    "    ## 1. Do not return the data.num_edges directly\n",
    "    ## 2. For undirected graphs, each edge is stored twice (once in each direction).\n",
    "    ## 3. Look at the PyG dataset built in functions\n",
    "    ## (~4 lines of code)\n",
    "\n",
    "    if dataset[idx].is_undirected():\n",
    "        num_edges = int(dataset[idx].num_edges/2)\n",
    "    else:\n",
    "        num_edges = dataset[idx].num_edges\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return num_edges\n",
    "\n",
    "idx = 100\n",
    "num_edges = get_graph_num_edges(dataset, idx)\n",
    "print('Graph with index {} has {} edges'.format(idx, num_edges))\n",
    "print(int(dataset[idx].edge_index.shape[1]/2) == num_edges)\n",
    "# It's True because edge_index stores the bi-directional edge information, for example an undirected edege between node 2 and node 5 \n",
    "# is stored twice by [2, 5] and [5, 2] in edge_index of an Data object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4982d5c-afd6-4772-9d1d-c596caebdb38",
   "metadata": {},
   "source": [
    "## Split data using inductive setting\n",
    "Randomly divide the dataset into training set and test set using inductive setting where 80 percent of the whole dataset are in training set and the rest are divided into test dataset.\n",
    "\n",
    "Each datepoint in the dataset is a graph. So it is easier for us to wrap datasets using [`torch_geometric.loader.DataLoader`](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.DataLoader)' so as to be able to sample minibatches during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aec14f6-2446-4a54-a917-e67245ff0b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "def inductive_split(dataset, split_ratio, batch_size):\n",
    "    # TODO: Implement a function to split the dataset into training dataset and test dataset\n",
    "    # using inductive setting. \n",
    "    # dataset: The PyTorch Geometric graph dataset.\n",
    "    # split_ratio(float): Ratio of nodes to be used for training.\n",
    "    # batch_size(int): batch_size for the dataloader\n",
    "\n",
    "    ############# Your code here ############\n",
    "    # Shuffle the dataset\n",
    "    dataset = dataset.shuffle()\n",
    "    \n",
    "    # Split the dataset into train and test sets\n",
    "    size = int(split_ratio*len(dataset))\n",
    "    train_dataset = dataset[:size]\n",
    "    test_dataset = dataset[size:]\n",
    "    \n",
    "    # Wrap the datset using Dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return train_loader, test_loader\n",
    "    \n",
    "train_loader, test_loader = inductive_split(dataset, split_ratio=0.8, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5635d532-7e6c-4bff-a2f2-88cb75aaf420",
   "metadata": {},
   "source": [
    "## Build GCN Model\n",
    "In this exercise, we will implement **batch normalization, dropout, global pooling, and skip layer connection**. \n",
    "\n",
    "Implement your GCN model following the structure:\n",
    "\n",
    "input --> GCN layer1 --> Batch Normalization --> non-linear activation --> dropout --> GCN layer2 --> Batch Normalization --> non-linear activation --> dropout --> graph-level prediction head(global pooling) --> prediction MLP\n",
    "\n",
    "For initial input, also skip connections for the first GCN layer, that is, in addition to the above structure, you also have:\n",
    "input --> GCN layer2 --> Batch Normalization --> non-linear activation --> dropout --> graph-level prediction head(gloabl pooling) --> prediction MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3629da4-c190-4a00-9be2-ddf34fdd1fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, BatchNorm\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, output_channels, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # TODO: Implement a function that initializes GCNconv layers and batch normalizations\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. The parameters you can set for GCNConv include 'in_channels' and\n",
    "        ## 'out_channels'. For more information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n",
    "        ## 2. The only parameter you need to set for BatchNorm is 'num_features'\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.norm.BatchNorm.html\n",
    "\n",
    "        self.conv1 = GCNConv(input_channels, input_channels)\n",
    "        self.batch_norm1 = BatchNorm(input_channels)\n",
    "        \n",
    "        self.conv2 = GCNConv(input_channels, hidden_channels)\n",
    "        self.batch_norm2 = BatchNorm(hidden_channels)\n",
    "\n",
    "        self.out = torch.nn.Linear(hidden_channels, output_channels)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        \n",
    "        #########################################\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        # TODO: Implement a function that takes the feature tensor x and\n",
    "        # edge_index tensor and batch_index tensor and returns the prediction tensor \n",
    "\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        batch = data.batch\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## 1. torch.nn.functional.relu and torch.nn.functional.dropout are useful\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch.org/docs/stable/nn.functional.html\n",
    "        ## 2. We already import torch.nn.functional as F\n",
    "        ## 3. For initial input, also skip connection for the first GCN layer. \n",
    "        ## 4. Choose your prefered Global Pooling over the nodes to create graph level embeddings that can be used to\n",
    "        ## predict properties for the each graph. Remeber that the batch attribute will be essential \n",
    "        ## for performining Global Pooling over our mini-batch of graphs.\n",
    "\n",
    "        duplicate_x = x\n",
    "        \n",
    "        ## First GCN layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        duplicate_x_2 = x\n",
    "        ## Skip connection\n",
    "        x = duplicate_x + x\n",
    "        \n",
    "        ## Second GCN layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # print(x.shape)\n",
    "        ## Skip connection\n",
    "        x = duplicate_x_2 + x\n",
    "\n",
    "        ## Second GCN layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        ## Global Pooling \n",
    "        ## (~1 line of code)\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        ## Output layer\n",
    "        out = self.out(x)\n",
    "        \n",
    "        #########################################\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0027e3d7-dcd6-44e4-a3bc-efcfb4b735fc",
   "metadata": {},
   "source": [
    "## Training your model\n",
    "Classifying enzyme dataset is a hard task. So with a simple model like ours, the accuracy is not very high.\n",
    "\n",
    "You can refer to this https://paperswithcode.com/sota/graph-classification-on-enzymes website for accuracies of classifying enzyme dataset from different research papers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3108a93f-623b-47b2-a3a3-4c5a02b80231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 1.8657, Train Acc: 0.2354, Test Acc: 0.2250\n",
      "Epoch: 001, Loss: 1.7811, Train Acc: 0.2292, Test Acc: 0.2250\n",
      "Epoch: 002, Loss: 1.7513, Train Acc: 0.2229, Test Acc: 0.1833\n",
      "Epoch: 003, Loss: 1.7452, Train Acc: 0.2375, Test Acc: 0.2250\n",
      "Epoch: 004, Loss: 1.7358, Train Acc: 0.2479, Test Acc: 0.2083\n",
      "Epoch: 005, Loss: 1.7519, Train Acc: 0.2229, Test Acc: 0.2583\n",
      "Epoch: 006, Loss: 1.7053, Train Acc: 0.2083, Test Acc: 0.1833\n",
      "Epoch: 007, Loss: 1.7473, Train Acc: 0.2500, Test Acc: 0.2250\n",
      "Epoch: 008, Loss: 1.7153, Train Acc: 0.1979, Test Acc: 0.1833\n",
      "Epoch: 009, Loss: 1.7334, Train Acc: 0.1875, Test Acc: 0.2167\n",
      "Epoch: 010, Loss: 1.7469, Train Acc: 0.2542, Test Acc: 0.2333\n",
      "Epoch: 011, Loss: 1.7275, Train Acc: 0.2875, Test Acc: 0.2500\n",
      "Epoch: 012, Loss: 1.7142, Train Acc: 0.2625, Test Acc: 0.2417\n",
      "Epoch: 013, Loss: 1.7040, Train Acc: 0.2542, Test Acc: 0.2750\n",
      "Epoch: 014, Loss: 1.7071, Train Acc: 0.2792, Test Acc: 0.2417\n",
      "Epoch: 015, Loss: 1.7220, Train Acc: 0.2396, Test Acc: 0.2417\n",
      "Epoch: 016, Loss: 1.7104, Train Acc: 0.2000, Test Acc: 0.1750\n",
      "Epoch: 017, Loss: 1.7265, Train Acc: 0.2542, Test Acc: 0.2250\n",
      "Epoch: 018, Loss: 1.7044, Train Acc: 0.2979, Test Acc: 0.3000\n",
      "Epoch: 019, Loss: 1.7141, Train Acc: 0.2875, Test Acc: 0.2833\n",
      "Epoch: 020, Loss: 1.7299, Train Acc: 0.2458, Test Acc: 0.2333\n",
      "Epoch: 021, Loss: 1.6991, Train Acc: 0.2667, Test Acc: 0.2583\n",
      "Epoch: 022, Loss: 1.7309, Train Acc: 0.2396, Test Acc: 0.2250\n",
      "Epoch: 023, Loss: 1.7156, Train Acc: 0.2354, Test Acc: 0.2833\n",
      "Epoch: 024, Loss: 1.7009, Train Acc: 0.2062, Test Acc: 0.2167\n",
      "Epoch: 025, Loss: 1.7146, Train Acc: 0.2313, Test Acc: 0.2250\n",
      "Epoch: 026, Loss: 1.7080, Train Acc: 0.2292, Test Acc: 0.2417\n",
      "Epoch: 027, Loss: 1.7282, Train Acc: 0.2021, Test Acc: 0.1917\n",
      "Epoch: 028, Loss: 1.7131, Train Acc: 0.2396, Test Acc: 0.2333\n",
      "Epoch: 029, Loss: 1.7149, Train Acc: 0.2625, Test Acc: 0.2750\n",
      "Epoch: 030, Loss: 1.7045, Train Acc: 0.2562, Test Acc: 0.2583\n",
      "Epoch: 031, Loss: 1.6946, Train Acc: 0.2375, Test Acc: 0.2333\n",
      "Epoch: 032, Loss: 1.7455, Train Acc: 0.2042, Test Acc: 0.2417\n",
      "Epoch: 033, Loss: 1.7216, Train Acc: 0.2458, Test Acc: 0.2833\n",
      "Epoch: 034, Loss: 1.7636, Train Acc: 0.2396, Test Acc: 0.2750\n",
      "Epoch: 035, Loss: 1.7421, Train Acc: 0.2458, Test Acc: 0.1833\n",
      "Epoch: 036, Loss: 1.7256, Train Acc: 0.2562, Test Acc: 0.2333\n",
      "Epoch: 037, Loss: 1.7285, Train Acc: 0.2062, Test Acc: 0.2333\n",
      "Epoch: 038, Loss: 1.7502, Train Acc: 0.1708, Test Acc: 0.2167\n",
      "Epoch: 039, Loss: 1.7445, Train Acc: 0.2271, Test Acc: 0.1750\n",
      "Epoch: 040, Loss: 1.7544, Train Acc: 0.2562, Test Acc: 0.2167\n",
      "Epoch: 041, Loss: 1.7178, Train Acc: 0.2750, Test Acc: 0.2833\n",
      "Epoch: 042, Loss: 1.7199, Train Acc: 0.2625, Test Acc: 0.2333\n",
      "Epoch: 043, Loss: 1.7015, Train Acc: 0.2458, Test Acc: 0.1667\n",
      "Epoch: 044, Loss: 1.7386, Train Acc: 0.2271, Test Acc: 0.2000\n",
      "Epoch: 045, Loss: 1.7362, Train Acc: 0.2271, Test Acc: 0.1917\n",
      "Epoch: 046, Loss: 1.7541, Train Acc: 0.2479, Test Acc: 0.1750\n",
      "Epoch: 047, Loss: 1.7297, Train Acc: 0.2854, Test Acc: 0.1750\n",
      "Epoch: 048, Loss: 1.7224, Train Acc: 0.2604, Test Acc: 0.2500\n",
      "Epoch: 049, Loss: 1.7369, Train Acc: 0.2292, Test Acc: 0.1500\n"
     ]
    }
   ],
   "source": [
    "hidden_channels = 32\n",
    "GCNmodel = GCN(dataset.num_node_features, hidden_channels, dataset.num_classes, 0.5)\n",
    "\n",
    "# Define the optimizers for the models\n",
    "GCNoptimizer = torch.optim.Adam(GCNmodel.parameters(), lr=0.05)\n",
    "\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def accuracy(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        pred = model(data)\n",
    "        pred = pred.argmax(dim=1)\n",
    "        correct += int(pred.eq(data.y).sum().item())\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    return accuracy\n",
    "\n",
    "# Training Loop\n",
    "def train(model, optimizer):\n",
    "    model.train()\n",
    "    Tloss = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.cross_entropy(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        Tloss += loss.item() * data.num_graphs\n",
    "\n",
    "    return Tloss / len(train_loader.dataset)\n",
    "\n",
    "# Run the training and testing for GCN Model\n",
    "for epoch in range(50):\n",
    "    loss = train(GCNmodel, GCNoptimizer)\n",
    "    train_acc = accuracy(GCNmodel, train_loader)\n",
    "    test_acc = accuracy(GCNmodel, test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86483a8a-6a02-4b3e-94b8-fecc3e0be4ce",
   "metadata": {},
   "source": [
    "## Data Split Transductive Setting\n",
    "\n",
    "In a transductive setting, all nodes are used during both training and testing, but their labels are only revealed according to the split. \n",
    "\n",
    "A simple way to split your data transductively using masks to indicate which nodes belong to the training, validation, and test sets.\n",
    "\n",
    "Implement the transductive_split function below which takes a graph data object, splits the nodes into training, validation, and test sets according to the specified ratios, and adds boolean masks to the data object indicating whether each node is in the training, validation, or test set. \n",
    "\n",
    "In a transductive setting, all node features (data.x) are available during training, but the labels (data.y) are only revealed according to these masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4f047c7-e077-400b-9979-11aa6a280dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transductive_split(data, train_ratio=0.6, val_ratio=0.2, seed=42):\n",
    "    \n",
    "    # Perform a transductive split on a PyTorch Geometric graph data.\n",
    "    \n",
    "    # Parameters:\n",
    "    # data (Data): The PyTorch Geometric Data object representing the graph.\n",
    "    # train_ratio (float): Ratio of nodes to be used for training.\n",
    "    # val_ratio (float): Ratio of nodes to be used for validation.\n",
    "    # seed (int): Random seed for reproducibility.\n",
    "\n",
    "    # test_ratio is omitted because it should equal to 1 - train_ratio - val_ratio\n",
    "\n",
    "    # Returns:\n",
    "    # data (Data): The PyTorch Geometric Data object with added train_mask, val_mask, and test_mask attributes.\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    train_mask = None\n",
    "    val_mask = None\n",
    "    test_mask = None\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    # Number of nodes in the graph\n",
    "    num_nodes = data.num_nodes\n",
    "\n",
    "    # Indices of all nodes shuffled\n",
    "    indices = torch.randperm(num_nodes)\n",
    "    print (indices)\n",
    "\n",
    "    # Determine the split sizes\n",
    "    train_size = int(num_nodes * train_ratio)\n",
    "    val_size = int(num_nodes * val_ratio)\n",
    "\n",
    "    # Create masks indicating whether a node belongs to the train, validation, or test set\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    print (train_mask)\n",
    "\n",
    "    train_mask[indices[:train_size]] = True\n",
    "    val_mask[indices[train_size:train_size + val_size]] = True\n",
    "    test_mask[indices[train_size + val_size:]] = True\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    # Add masks to data\n",
    "    data.train_mask = train_mask\n",
    "    data.val_mask = val_mask\n",
    "    data.test_mask = test_mask\n",
    "\n",
    "    return data\n",
    "\n",
    "# Example usage:\n",
    "# Assume 'data' is your PyTorch Geometric Data object\n",
    "# data = Data(x=node_features, edge_index=edge_indices, y=node_labels)  # Example initialization\n",
    "\n",
    "# Perform the transductive split\n",
    "# data = transductive_split(data, train_ratio=0.6, val_ratio=0.2)\n",
    "\n",
    "# Now 'data' contains 'train_mask', 'val_mask', and 'test_mask' which can be used to mask the nodes for training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c202cd2a-f812-41a9-a5d2-d79705e6ae8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([30,  0,  1, 17, 10,  6, 18,  2, 26, 22, 20, 24,  8, 31, 25,  9, 27, 16,\n",
      "        14,  4, 21, 15, 23, 29, 33, 19, 13, 28,  5, 11,  7, 12,  3, 32])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False])\n",
      "tensor([ True,  True,  True, False,  True, False,  True, False,  True,  True,\n",
      "         True, False, False, False,  True, False,  True,  True,  True, False,\n",
      "         True, False,  True, False,  True,  True,  True,  True, False, False,\n",
      "         True,  True, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False, False,  True,\n",
      "        False,  True, False,  True, False, False, False, False, False,  True,\n",
      "        False, False, False,  True])\n",
      "tensor([False, False, False,  True, False,  True, False,  True, False, False,\n",
      "        False,  True,  True,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False,  True, False])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import KarateClub\n",
    "\n",
    "# Load the Karate Club dataset\n",
    "dataset = KarateClub()\n",
    "data = dataset[0]  # Get the graph Data object\n",
    "\n",
    "# Perform the transductive split\n",
    "data = transductive_split(data, train_ratio=0.6, val_ratio=0.2)\n",
    "\n",
    "print(data.train_mask)\n",
    "print(data.val_mask)\n",
    "print(data.test_mask)\n",
    "# count the number of True and False in the mask attributes. Do they match the ratios? You can also play with the radios.\n",
    "# \"True\" basically means the node's label is fed into training/validation/test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e403417-4e13-4d50-98bc-b22dbf577623",
   "metadata": {},
   "source": [
    "## Graph Manipulation\n",
    "In this exercise, we use the KarateClub data as an example to perform the following tasks.\n",
    "\n",
    "Tasks:\n",
    "1. constant node features or one-hot node features?\n",
    "2. Add virtual node / edge (for sparse graph)\n",
    "3. Sample subgraph / neighours (for dense / large graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c5b9ac4-1d4a-4ec3-9443-e4b22c2d246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node features\n",
    "# get the node features of a graph dataset, are the node features constant node features or one-hot node features\n",
    "def check_node_features(data):\n",
    "\n",
    "    ############# Your code here ############\n",
    "    # get node feature matrix\n",
    "    x = data.x \n",
    "\n",
    "    print (torch.all(x == x[0], dim=0))\n",
    "    \n",
    "    # Check if features are constant\n",
    "    if torch.all(x == x[0], dim=0).all():\n",
    "        return \"The node features are constant across all nodes.\"\n",
    "\n",
    "    # Check if features are one-hot node features (each node has a unique one-hot id)\n",
    "    # One-Hot Criterion: Check if each row sums to 1 and contains exactly one '1'\n",
    "    row_sums = torch.sum(x, dim=1)\n",
    "    one_hot_criterion = torch.all(row_sums == 1) and torch.all((x == 0) | (x == 1)) ## each row sums to 1 and \n",
    "                                                                                    ## the matrix only contains 0s and 1s\n",
    "    print (one_hot_criterion)\n",
    "    \n",
    "    # Uniqueness Criterion: Check if all rows are unique\n",
    "    # we sum up the columns, each column should also sum to 1 if all rows are unique\n",
    "    col_sums = torch.sum(x, dim=0)\n",
    "    uniqueness_criterion = torch.all(col_sums == 1)\n",
    "    if one_hot_criterion and uniqueness_criterion:\n",
    "        return \"The node features are one-hot encoded.\"\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return \"The node features are neither constant across all nodes nor one-hot encoded.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fcce54c-16be-4d95-b17f-0913126c17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False])\n",
      "tensor(True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The node features are one-hot encoded.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Karate Club dataset\n",
    "dataset = KarateClub()\n",
    "data = dataset[0]  # Get the graph Data object\n",
    "\n",
    "check_node_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1440115e-6e60-40d3-96cc-ee5822c842c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add virtual Edge/nodes\n",
    "def add_virtual_node(data):\n",
    "    # data (Data): The PyTorch Geometric Data object representing the graph.\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    num_nodes = data.num_nodes\n",
    "\n",
    "    # Add a virtual node to the node feature matrix\n",
    "    # 1. generate the virtual node features as the mean of exisiting features.\n",
    "    # 2. add the virtual node features to the existing node feature matrix. \n",
    "    \n",
    "    virtual_node_features = torch.mean(data.x, dim=0, keepdim=True)  # Example: using the mean of existing features\n",
    "    data.x = torch.cat([data.x, virtual_node_features], dim=0)\n",
    "\n",
    "    # Connect the virtual node to all existing nodes\n",
    "    # Assume all edges are undirected\n",
    "    # 1. create the tensor for connecting edges\n",
    "    # 2. making the edge undirected as how the Pytorch Geometric Data object would represent a undirected edge\n",
    "   \n",
    "    virtual_node_edges = torch.tensor([[num_nodes] * num_nodes, list(range(num_nodes))], dtype=torch.long)\n",
    "    print (virtual_node_edges)\n",
    "    virtual_node_edges = torch.cat([virtual_node_edges, virtual_node_edges.flip(0)], dim=1)  # Making it undirected\n",
    "\n",
    "    # Add these edges to the edge index\n",
    "    data.edge_index = torch.cat([data.edge_index, virtual_node_edges], dim=1)\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f811a88-7a20-444a-9586-bb5bdfe2447b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 156])\n",
      "tensor([[34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
      "         34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]])\n",
      "torch.Size([2, 224])\n"
     ]
    }
   ],
   "source": [
    "# Load the Karate Club dataset\n",
    "dataset = KarateClub()\n",
    "data = dataset[0]  # Get the graph Data object\n",
    "print(data.edge_index.shape)\n",
    "data=add_virtual_node(data)\n",
    "print(data.edge_index.shape)\n",
    "# You should find out that the added node is connected to all the existing nodes. \n",
    "# Understanding edge_index: edge_index[0][i] is connected to edge_index[1][i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6406f36f-0103-413a-9212-a372a04769e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample neighours for a given node \n",
    "import random \n",
    "\n",
    "def sample_neighbors(data, node_id, sample_neigh_num):\n",
    "    # data (Data): The PyTorch Geometric Data object representing the graph.\n",
    "    # node_id (int): The ID of the node for which to find neighbors.\n",
    "    # sample_neigh_num(int): The number of neighbours to sample each time. \n",
    "    \n",
    "    ############# Your code here ############ \n",
    "    \n",
    "    # Find all the neighours of the specified node\n",
    "    all_neighbours = []\n",
    "    for idx in range(len(data.edge_index[0])):\n",
    "        node = data.edge_index[0][idx]\n",
    "        if node == node_id:\n",
    "            neighbor = int(data.edge_index[1][idx])\n",
    "            all_neighbours.append(neighbor)\n",
    "\n",
    "    print (all_neighbours)\n",
    "    \n",
    "    # Randomly sample neighbours from all neighbours\n",
    "    # return the sampled neighbour nodes\n",
    "    if sample_neigh_num >= len(all_neighbours): ## do not have enough neighbours to sample. Keep all neigbour nodes\n",
    "        sampled = all_neighbours\n",
    "    else:\n",
    "        sampled = random.sample(all_neighbours, sample_neigh_num)\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d253b6ee-1d21-446a-94c7-5472f44ba50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 17, 19, 21, 31]\n",
      "[13, 6, 31]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 17, 19, 21, 31]\n",
      "[21, 13, 6]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 17, 19, 21, 31]\n",
      "[8, 21, 10]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 17, 19, 21, 31]\n",
      "[8, 4, 11]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 17, 19, 21, 31]\n",
      "[21, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "dataset = KarateClub()\n",
    "data = dataset[0]\n",
    "\n",
    "# Specify the node for which to sample neighbors\n",
    "node_id = 0  # For example, node 0\n",
    "\n",
    "# Sample 3 neighbors for the specified node each time for 5 times\n",
    "for i in range(5):\n",
    "    sampled = sample_neighbors(data, node_id, 3)\n",
    "    print(sampled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kaveh)",
   "language": "python",
   "name": "kaveh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
